{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvDzjTwXHLjj"
      },
      "source": [
        "## Rebuilding other architectures\n",
        "Maybe we can add some smart tricks from price winning architectures. If you have read the book, you have seen some smart architectures. We can build those by small units by hand, and add layers like that. Maybe these smart ideas can help us out. The InceptionUnit would look like this:\n",
        "\n",
        "<img src=https://images.deepai.org/django-summernote/2019-06-18/2cec735b-2347-4ded-ae2b-e8a8384f7b46.png width=600/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vBM-o5iWd3iS"
      },
      "outputs": [],
      "source": [
        "class InceptionUnit(tf.keras.layers.Layer):\n",
        "    def __init__(self, conv1_filters, conv3_filters, conv5_filters, conv1_max_filters, pre_conv3_filters, \n",
        "                 pre_conv5_filters, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=conv1_filters, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=conv3_filters, kernel_size=3, strides=1, padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(filters=conv5_filters, kernel_size=5, strides=1, padding='same', activation='relu')\n",
        "        self.conv1_max = tf.keras.layers.Conv2D(filters=conv1_max_filters, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "        self.pre_conv3 = tf.keras.layers.Conv2D(filters=pre_conv3_filters, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "        self.pre_conv5 = tf.keras.layers.Conv2D(filters=pre_conv5_filters, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "        self.pre_conv1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=1, padding='same')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        c1 = self.conv1(inputs)\n",
        "        pre_c3 = self.pre_conv3(inputs)\n",
        "        c3 = self.conv3(pre_c3)\n",
        "        pre_c5 = self.pre_conv5(inputs)\n",
        "        c5 = self.conv5(pre_c5)\n",
        "        pre_c1m = self.pre_conv1(inputs)\n",
        "        c1m = self.conv1_max(pre_c1m)\n",
        "        out = tf.concat([c1, c3, c5, c1m], axis=3)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQlbzenPHLjk"
      },
      "source": [
        "Even though your model does not have to look as complex as this, you might still get some inspiration from this architecture. For example, note how the datastream is duplicated and fed through filters of a different size. That might be an interesting idea, in a simplified model.\n",
        "\n",
        "Another architecture is ResNet. A ResNet module would  be build like this, with a skip layer.\n",
        "\n",
        "\n",
        "<img src=http://d2l.ai/_images/resnet-block.svg \n",
        "     width=700/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0rnTEZj0SaBS"
      },
      "outputs": [],
      "source": [
        "class ResidualUnit(tf.keras.layers.Layer):\n",
        "  # when the layer is initialized, we create some default elements\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "      super().__init__(**kwargs)\n",
        "      # a general activation\n",
        "      self.activation = tf.keras.activations.get(activation)\n",
        "      # the main layers with 3x3 kernels \n",
        "      self.main_layers = [\n",
        "          Conv2D(filters, kernel_size=3, strides=strides, padding='same'),\n",
        "          BatchNormalization(),\n",
        "          self.activation,\n",
        "          Conv2D(filters, kernel_size=3, strides=1, padding='same'),\n",
        "          BatchNormalization()]\n",
        "      # and the skip layer, sometimes with a 1x1 kernel Conv2D    \n",
        "      self.skip_layers = []\n",
        "      if strides > 1:\n",
        "          self.skip_layers = [\n",
        "              Conv2D(filters, kernel_size=1, strides=strides),\n",
        "              BatchNormalization()]\n",
        "\n",
        "    # the main architecture.\n",
        "    # we walk through the main layers, and add the skip layer at the end.\n",
        "    def call(self, inputs):\n",
        "      Z = inputs\n",
        "      for layer in self.main_layers:\n",
        "        Z = layer(Z)\n",
        "      skip_Z = inputs\n",
        "      for layer in self.skip_layers:\n",
        "        skip_Z = layer(skip_Z)\n",
        "      return self.activation(Z + skip_Z)\n",
        "    \n",
        "    # this is not essential, but can sometimes give errors if left out when saving the model.\n",
        "    # this mainly returns the elements that where set on initialization.\n",
        "    def get_config(self):\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "        'activation': self.activation,\n",
        "        'main_layers': self.main_layers,\n",
        "        'skip_layers': self.skip_layers\n",
        "        })\n",
        "      return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-21 13:20:06.836 | INFO     | src.data.make_dataset:get_raw_data:18 - found flowers in ../data/raw, not downloading again\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"..\")\n",
        "from pathlib import Path\n",
        "from src.data import make_dataset\n",
        "data_dir = Path(\"../data/raw\")\n",
        "make_dataset.get_raw_data(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "flowers_dir = Path(\"../data/raw/flower_photos\")\n",
        "flowers_dir.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ],
      "source": [
        "targetsize = (150, 150)\n",
        "train, valid = make_dataset.dataset_from_dir(flowers_dir, targetsize=targetsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaTQ8Mi8HLjk"
      },
      "source": [
        "Let's rebuild the complete architecture from [ResNet34](https://arxiv.org/pdf/1512.03385.pdf).\n",
        "From their paper:\n",
        ">We use SGD with a mini-batch size of 256. The learning rate starts from 0.1 and is divided by 10 when the error plateaus, and the models are trained for up to $60\\times 10^4$ iterations. We use a weight decay of 0.0001 and a momentum of 0.9. We do not use dropout\n",
        "\n",
        "And the table from their paper with architectures for different depths:\n",
        "<img src=https://miro.medium.com/max/1400/1*aq0q7gCvuNUqnMHh4cpnIw.png width=600/>\n",
        "\n",
        "Let us implement the 34-layer ResNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aQ9bh5tKXPMG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Activation,\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    BatchNormalization, \n",
        "    MaxPool2D, \n",
        "    GlobalAveragePooling2D,\n",
        "    Dense,\n",
        ")\n",
        "\n",
        "input = Input(shape = targetsize+ (3,))\n",
        "x = Conv2D(64, 7, strides=2, padding='same')(input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "prev = 64\n",
        "for filters in [64]*3+[128]*4+[256]*6+[512]*3:\n",
        "    strides=1 if filters == prev else 2\n",
        "    x = ResidualUnit(filters, strides=strides)(x)\n",
        "    prev = filters\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Dense(5)(x)\n",
        "\n",
        "model = tf.keras.Model(inputs = [input], outputs=[output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "asFWiRArNtQa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "optimizer = SGD(learning_rate=1e-3, momentum=0.9)\n",
        "\n",
        "model.compile(\n",
        "  optimizer=optimizer,\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "durISha7NSi7",
        "outputId": "4b111c9e-eeab-4880-9d1a-bd1053ca7893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 75, 75, 64)        9472      \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 75, 75, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 38, 38, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " residual_unit_16 (ResidualU  (None, 38, 38, 64)       74368     \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_17 (ResidualU  (None, 38, 38, 64)       74368     \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_18 (ResidualU  (None, 38, 38, 64)       74368     \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_19 (ResidualU  (None, 19, 19, 128)      231296    \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_20 (ResidualU  (None, 19, 19, 128)      296192    \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_21 (ResidualU  (None, 19, 19, 128)      296192    \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_22 (ResidualU  (None, 19, 19, 128)      296192    \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_23 (ResidualU  (None, 10, 10, 256)      921344    \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_24 (ResidualU  (None, 10, 10, 256)      1182208   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_25 (ResidualU  (None, 10, 10, 256)      1182208   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_26 (ResidualU  (None, 10, 10, 256)      1182208   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_27 (ResidualU  (None, 10, 10, 256)      1182208   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_28 (ResidualU  (None, 10, 10, 256)      1182208   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_29 (ResidualU  (None, 5, 5, 512)        3677696   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_30 (ResidualU  (None, 5, 5, 512)        4723712   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_31 (ResidualU  (None, 5, 5, 512)        4723712   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,312,773\n",
            "Trainable params: 21,295,749\n",
            "Non-trainable params: 17,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwhqHUDpIinF"
      },
      "source": [
        "Note, how the image is reduced to 7x7 squares, while the amount of channels grows into 512 different features! Also, the hidden Dense layers are completely removed! We have just one Dense layer as the output, and the model is a full stack of Conv2D layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDSAKzsKOgzo",
        "outputId": "1e9ae25e-113c-4928-c318-7ab18a749ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 5/92 [>.............................] - ETA: 3:56 - loss: 2.1248 - accuracy: 0.2313"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/hf/21nm0lc549l9xq9rr527gj5c0000gn/T/ipykernel_75013/1268475871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/hu-deeplearning-R-urKDRm-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
        "logdir = Path(\"logs/resnet\")\n",
        "cb = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_lr=0.01)\n",
        "tb = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.fit(\n",
        "  train,\n",
        "  validation_data=valid,\n",
        "  callbacks=[cb, tb],\n",
        "  epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVZzMDv4WxFz"
      },
      "source": [
        "This will take over an hour for 100 epochs, even with a GPU on colab (note that you can't leave your model unattended on colab; if you laptop goes to sleep, colab might shut down your machine). \n",
        "But after 80 epochs, I got over 80%!\n",
        "\n",
        "If you try this on the hub (that does not has enough RAM), or on a laptop with RAM below 16GB, it will crash the jupyter notebook due to the RAM memory the model needs. \n",
        "\n",
        "Yet, on colab it does train and the accuracy will get above 80% and is still slowly increasing. And if you have a machine where you can keep this running, unattended, an hour is no problem at all.\n",
        "\n",
        "Also, realize that the ResNet they used to win a prize was trained for sixty thousands epochs!! Again, that is a complete new order of training your model..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deeplearn3-20201221-2217.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "fd838b4e8e084a6a759aff6a24fadbf2445d28874d00da48c8398869c390159d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
