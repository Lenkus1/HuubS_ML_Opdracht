{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (1.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (1.21.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (2.26.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (2.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (1.7.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from keras-tuner) (7.30.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (58.3.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (3.0.24)\n",
      "Requirement already satisfied: pygments in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (2.10.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (5.1.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from ipython->keras-tuner) (0.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from packaging->keras-tuner) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from requests->keras-tuner) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from requests->keras-tuner) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from requests->keras-tuner) (2021.10.8)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (3.19.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (1.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (2.3.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.6)\n",
      "Requirement already satisfied: six in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from absl-py>=0.4->tensorboard->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hjtfs\\appdata\\local\\pypoetry\\cache\\virtualenvs\\hu-deeplearning-lsm0ezyv-py3.8\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjtfs\\AppData\\Local\\Temp/ipykernel_11140/1167079941.py:29: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pip install keras-tuner\n",
    "import datetime\n",
    "tick = datetime.datetime.now()\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D, Input, Dropout, GlobalAveragePooling2D, Lambda, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import requests\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from kerastuner import HyperModel\n",
    "from keras_tuner.tuners import Hyperband\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from src.data import make_dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_processed = Path(\"../data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for f in sorted(os.listdir(datadir_processed)):\n",
    "    folder = os.path.join(datadir_processed, f)\n",
    "    if os.path.isdir(folder):\n",
    "        #print(f\"{f} is a target class\")\n",
    "        for i in sorted(os.listdir(folder)):\n",
    "            image=tf.keras.preprocessing.image.load_img(folder+'/'+i, \n",
    "            target_size= (64,64))\n",
    "            image=np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(f)\n",
    "\n",
    "data = np.array(data)\n",
    "#labels = np.array(labels)\n",
    "labels = list(labels)\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2,\n",
    "                                                random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Pre-processing\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (64, 64, 3)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=3,\n",
    "        activation='relu',\n",
    "        input_shape=INPUT_SHAPE\n",
    "    )\n",
    ")\n",
    "model.add(Conv2D(16, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                activation='relu'\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=hp.Choice(\n",
    "                    'num_filters',\n",
    "                    values=[32, 64],\n",
    "                    default=64,\n",
    "                ),\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_2',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_3',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "                )\n",
    "            ),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "#hypermodel = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperband\\Galaxies\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hyperband\\Galaxies\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 10  #number of classes\n",
    "INPUT_SHAPE = (64, 64, 3)  # images input shape\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "\n",
    "HYPERBAND_MAX_EPOCHS = 20\n",
    "MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "SEED=123\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_accuracy',\n",
    "    seed=SEED,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='hyperband',\n",
    "    project_name='Galaxies',\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': None}\n",
      "num_filters (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': None}\n",
      "units (Int)\n",
      "{'default': 128, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "dense_activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "dropout_3 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 Complete [00h 10m 04s]\n",
      "val_accuracy: 0.5701198279857635\n",
      "\n",
      "Best val_accuracy So Far: 0.6712473630905151\n",
      "Total elapsed time: 04h 55m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Save the checkpoint in the /output folder\n",
    "filepath = Path(\"../data/hyperband\")\n",
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "N_EPOCH_SEARCH = 20\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=N_EPOCH_SEARCH, validation_split=0.1,callbacks=[tf.keras.callbacks.EarlyStopping('val_accuracy', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperband\\Galaxies\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.1\n",
      "num_filters: 64\n",
      "dropout_2: 0.15000000000000002\n",
      "units: 448\n",
      "dense_activation: sigmoid\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.0012633033032926032\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 55b290453a2385b0c2b4a545178ad0fe\n",
      "Score: 0.6712473630905151\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.30000000000000004\n",
      "num_filters: 64\n",
      "dropout_2: 0.1\n",
      "units: 256\n",
      "dense_activation: relu\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.0009211376149271358\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6712473630905151\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.1\n",
      "num_filters: 64\n",
      "dropout_2: 0.05\n",
      "units: 128\n",
      "dense_activation: tanh\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.000414752791265096\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: fe8427bc563a543de48fb451ed9926b1\n",
      "Score: 0.6708950102329254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.0\n",
      "num_filters: 64\n",
      "dropout_2: 0.25\n",
      "units: 288\n",
      "dense_activation: tanh\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.0012172862812975754\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: c7f9df1ffe455145e656a9f2fe0ed103\n",
      "Score: 0.6698379218578339\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.0\n",
      "num_filters: 64\n",
      "dropout_2: 0.25\n",
      "units: 288\n",
      "dense_activation: tanh\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.0012172862812975754\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 469ad6d57b49f9d3502696c7bba1003a\n",
      "Score: 0.6691332161426544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.30000000000000004\n",
      "num_filters: 64\n",
      "dropout_2: 0.1\n",
      "units: 256\n",
      "dense_activation: relu\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.0009211376149271358\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: b5c59775bb77c7ac57fc313bc76c0718\n",
      "Score: 0.66560959815979\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.35000000000000003\n",
      "num_filters: 32\n",
      "dropout_2: 0.25\n",
      "units: 320\n",
      "dense_activation: tanh\n",
      "dropout_3: 0.5\n",
      "learning_rate: 0.0005512644277558126\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 5706692391c885139a8fecfc9a1282e0\n",
      "Score: 0.6642001271247864\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.1\n",
      "num_filters: 64\n",
      "dropout_2: 0.05\n",
      "units: 128\n",
      "dense_activation: tanh\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.000414752791265096\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: d0970b32d3df3426c593b065d327a9b2\n",
      "Score: 0.6603241562843323\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.1\n",
      "num_filters: 64\n",
      "dropout_2: 0.15000000000000002\n",
      "units: 448\n",
      "dense_activation: sigmoid\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.0012633033032926032\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: e03aaef0f21ece7a63d7917735fd8fc6\n",
      "Score: 0.6557434797286987\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.25\n",
      "num_filters: 64\n",
      "dropout_2: 0.35000000000000003\n",
      "units: 96\n",
      "dense_activation: relu\n",
      "dropout_3: 0.0\n",
      "learning_rate: 0.000520348319313704\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: e7485c9d8a40b3996cf9a2c43e8c0508\n",
      "Score: 0.6472868025302887\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 1.0463 - accuracy: 0.6776\n"
     ]
    }
   ],
   "source": [
    "# Show a summary of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# Retrieve the best model.\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model.\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d031ad01bed61ded824456c2d8715b797c0f37e7c3a3e3c3c540f3dac9fb955e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('hu-deeplearning-lSm0EZYV-py3.8': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
